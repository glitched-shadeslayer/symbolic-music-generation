{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee88bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\1212626047.py:27: UserWarning: You are using a depreciated `miditoolkit.MidiFile` object. MidiTokis now (>v3.0.0) using symusic.Score as MIDI backend. Your file willbe converted on the fly, however please consider using symusic.\n",
      "  tokens = tokenizer(midi)\n",
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\1212626047.py:38: UserWarning: miditok: The `save_params` method had been renamed `save`. It is now depreciated and will be removed in future updates.\n",
      "  tokenizer.save_params(token_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jig average BPM: 120.00, us/quarter: 500000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 44.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 43.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:01<00:00, 41.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 42.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:01<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 45.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 44.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 44.17it/s]\n",
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\1212626047.py:215: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  midi_obj = tokenizer.tokens_to_midi([seq])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\1212626047.py:243: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  midi = dataset.tokenizer.tokens_to_midi([tokens])\n"
     ]
    }
   ],
   "source": [
    "import miditok\n",
    "import miditoolkit\n",
    "import os\n",
    "import json\n",
    "\n",
    "melody_folder = 'MIDI/melody'\n",
    "token_folder = 'nottingham_tokens'\n",
    "os.makedirs(token_folder, exist_ok=True)\n",
    "\n",
    "tokenizer = miditok.REMI()\n",
    "\n",
    "def get_token_ids(tokens):\n",
    "    # Case 1: tokens is a TokSequence\n",
    "    if hasattr(tokens, \"ids\"):\n",
    "        return tokens.ids\n",
    "    # Case 2: tokens is a list of TokSequence\n",
    "    if isinstance(tokens, list) and len(tokens) > 0 and hasattr(tokens[0], \"ids\"):\n",
    "        return [t.ids for t in tokens]\n",
    "    # Case 3: tokens is a plain list (already token IDs)\n",
    "    return tokens\n",
    "\n",
    "jig_tempos = []\n",
    "\n",
    "for fname in os.listdir(melody_folder):\n",
    "    if fname.endswith('.mid') and fname.lower().startswith(\"jigs\"):\n",
    "        midi = miditoolkit.MidiFile(os.path.join(melody_folder, fname))\n",
    "        tokens = tokenizer(midi)\n",
    "        token_ids = get_token_ids(tokens)\n",
    "        # ---- Store tempo for average calculation ----\n",
    "        if midi.tempo_changes:\n",
    "            jig_tempos.append(midi.tempo_changes[0].tempo)\n",
    "        else:\n",
    "            jig_tempos.append(120)  # Fallback/default if not set\n",
    "        # ---- Save tokenized output as before ----\n",
    "        with open(os.path.join(token_folder, fname.replace('.mid', '.json')), \"w\") as fp:\n",
    "            json.dump({'ids': token_ids}, fp)\n",
    "\n",
    "tokenizer.save_params(token_folder)\n",
    "\n",
    "# ---- Calculate average BPM for jigs ----\n",
    "avg_bpm = sum(jig_tempos) / len(jig_tempos) if jig_tempos else 120\n",
    "avg_us_per_quarter = 60_000_000 / avg_bpm\n",
    "print(f\"Jig average BPM: {avg_bpm:.2f}, us/quarter: {avg_us_per_quarter:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, token_folder):\n",
    "        self.files = [\n",
    "            os.path.join(token_folder, f)\n",
    "            for f in os.listdir(token_folder)\n",
    "            if f.endswith(\".json\") and f != \"tokenizer.json\" and f.lower().startswith(\"jigs\")\n",
    "        ]\n",
    "        param_path = os.path.join(token_folder, \"tokenizer.json\")\n",
    "        self.tokenizer = miditok.REMI(params=param_path)\n",
    "        self.sequences = []\n",
    "        for file in self.files:\n",
    "            with open(file, \"r\") as fp:\n",
    "                tok_seq = json.load(fp)\n",
    "            if 'ids' in tok_seq:\n",
    "                self.sequences.append(tok_seq['ids'])\n",
    "            else:\n",
    "                print(f\"Skipping {file} (no 'ids' key)\")\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        x = torch.tensor(seq[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "dataset = MIDITokenDataset(token_folder)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_positional_encoding(seq_len, d_model, device):\n",
    "    position = torch.arange(seq_len, dtype=torch.float, device=device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, device=device).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "    pe = torch.zeros(seq_len, d_model, device=device)\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "class MusicTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=256,\n",
    "        nhead=8,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward, dropout\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq)\n",
    "        batch_size, seq_len = x.shape\n",
    "        pos_enc = get_positional_encoding(seq_len, self.embed.embedding_dim, x.device).unsqueeze(0)\n",
    "        x = self.embed(x) + pos_enc\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.transformer(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = len(dataset.tokenizer.vocab)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MusicTransformer(vocab_size).to(device)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out.view(-1, out.size(-1)), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "\n",
    "def generate_until_duration(model, tokenizer, device, target_seconds=120, temperature=1.0, max_tokens=2000):\n",
    "    model.eval()\n",
    "    start_token = list(tokenizer.vocab.values())[0]\n",
    "    seq = [start_token]\n",
    "    x = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "    elapsed_seconds = 0\n",
    "\n",
    "    TPQ = 480\n",
    "    tempo_us_per_quarter = 500_000  # 120 BPM by default\n",
    "\n",
    "    while elapsed_seconds < target_seconds and len(seq) < max_tokens:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        seq.append(next_token)\n",
    "        x = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "\n",
    "        if len(seq) % 32 == 0 or elapsed_seconds == 0:\n",
    "            midi_obj = tokenizer.tokens_to_midi([seq])\n",
    "            ticks = midi_obj.end()\n",
    "            elapsed_seconds = ticks / TPQ * (tempo_us_per_quarter / 1_000_000)\n",
    "\n",
    "    return seq\n",
    "\n",
    "def generate_until_duration_smart(\n",
    "    model, tokenizer, device, target_seconds=25, temperature=1.0, max_tokens=3000,\n",
    "    tpq=480, tempo_us_per_quarter=500_000, max_tokens_per_beat=4\n",
    "):\n",
    "    model.eval()\n",
    "    start_token = list(tokenizer.vocab.values())[0]\n",
    "    seq = [start_token]\n",
    "    x = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "    elapsed_seconds = 0\n",
    "    tokens_in_current_beat = 0\n",
    "\n",
    "    # Get time-shift token IDs for the tokenizer\n",
    "    time_shift_token_ids = [\n",
    "        tid for t, tid in tokenizer.vocab.items() if t.startswith(\"TimeShift\")\n",
    "    ]\n",
    "    # (For REMI, \"TimeShift_XX\" are the time advance tokens.)\n",
    "\n",
    "    while elapsed_seconds < target_seconds and len(seq) < max_tokens:\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        # Check if the next token is a time-shift\n",
    "        if next_token in time_shift_token_ids:\n",
    "            tokens_in_current_beat = 0\n",
    "        else:\n",
    "            tokens_in_current_beat += 1\n",
    "\n",
    "        # If tokens in this beat exceed limit, force a time-shift\n",
    "        if tokens_in_current_beat > max_tokens_per_beat:\n",
    "            time_shift_token_ids = [\n",
    "                tid for t, tid in tokenizer.vocab.items() if \"shift\" in t.lower()\n",
    "            ]\n",
    "            tokens_in_current_beat = 0\n",
    "\n",
    "        seq.append(next_token)\n",
    "        x = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "\n",
    "        # Periodically check duration\n",
    "        if len(seq) % 32 == 0 or elapsed_seconds == 0:\n",
    "            midi_obj = tokenizer.tokens_to_midi([seq])\n",
    "            ticks = midi_obj.end()\n",
    "            elapsed_seconds = ticks / tpq * (tempo_us_per_quarter / 1_000_000)\n",
    "\n",
    "    return seq\n",
    "\n",
    "\n",
    "# tokens = generate_until_duration(\n",
    "#     model,\n",
    "#     dataset.tokenizer,\n",
    "#     device=device,\n",
    "#     target_seconds=27,\n",
    "#     temperature=1.0,\n",
    "#     max_tokens=3000  # Safety upper limit for shorter jigs\n",
    "# )\n",
    "\n",
    "tokens = generate_until_duration_smart(\n",
    "    model,\n",
    "    dataset.tokenizer,\n",
    "    device=device,\n",
    "    target_seconds=25,  # e.g., 25 seconds\n",
    "    temperature=1.0,\n",
    "    max_tokens=3000,\n",
    "    tpq=480,\n",
    "    tempo_us_per_quarter=avg_us_per_quarter,\n",
    "    max_tokens_per_beat=4\n",
    ")\n",
    "\n",
    "midi = dataset.tokenizer.tokens_to_midi([tokens])\n",
    "midi.dump_midi(\"generated_jig.mid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe2a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration (seconds): 26.31\n"
     ]
    }
   ],
   "source": [
    "# To verify duration\n",
    "from symusic.core import ScoreTick\n",
    "\n",
    "midi_loaded = ScoreTick.from_file(\"generated_jig.mid\")\n",
    "duration_seconds = midi_loaded.end() / midi_loaded.ticks_per_quarter * 60 / 120\n",
    "print(f\"Duration (seconds): {duration_seconds:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe39b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\3195021264.py:29: UserWarning: You are using a depreciated `miditoolkit.MidiFile` object. MidiTokis now (>v3.0.0) using symusic.Score as MIDI backend. Your file willbe converted on the fly, however please consider using symusic.\n",
      "  tokens = tokenizer(midi)\n",
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\3195021264.py:45: UserWarning: miditok: The `save_params` method had been renamed `save`. It is now depreciated and will be removed in future updates.\n",
      "  tokenizer.save_params(token_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jig average BPM: 120.00, us/quarter: 500000.00\n",
      "Loaded 340 sequences.\n",
      "Skipped 0 files: [] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 42/42 [24:22<00:00, 34.83s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 42/42 [20:25<00:00, 29.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.4072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 42/42 [18:10<00:00, 25.97s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 42/42 [18:08<00:00, 25.91s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 42/42 [19:18<00:00, 27.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.9371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 42/42 [18:16<00:00, 26.10s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 42/42 [18:42<00:00, 26.73s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 42/42 [21:07<00:00, 30.19s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 42/42 [23:48<00:00, 34.00s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.8187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 42/42 [23:53<00:00, 34.13s/it] \n",
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\3195021264.py:150: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  midi_obj = tokenizer.tokens_to_midi([seq])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.8106\n",
      "Saved generated_jig_lstm.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\AppData\\Local\\Temp\\ipykernel_67376\\3195021264.py:166: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  midi = dataset.tokenizer.tokens_to_midi([tokens])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import miditok\n",
    "import miditoolkit\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Tokenize Jigs MIDI ===\n",
    "melody_folder = 'MIDI/melody'  # Update as needed\n",
    "token_folder = 'nottingham_tokens'\n",
    "os.makedirs(token_folder, exist_ok=True)\n",
    "tokenizer = miditok.REMI()\n",
    "\n",
    "def get_token_ids(tokens):\n",
    "    if hasattr(tokens, \"ids\"):\n",
    "        return tokens.ids\n",
    "    if isinstance(tokens, list) and len(tokens) > 0 and hasattr(tokens[0], \"ids\"):\n",
    "        return [t.ids for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "jig_tempos = []\n",
    "for fname in os.listdir(melody_folder):\n",
    "    if fname.endswith('.mid') and fname.lower().startswith(\"jigs\"):\n",
    "        midi = miditoolkit.MidiFile(os.path.join(melody_folder, fname))\n",
    "        tokens = tokenizer(midi)\n",
    "        # tokens might be a TokSequence or a list of TokSequence!\n",
    "        if isinstance(tokens, list):  # If it's a list, flatten all ids\n",
    "            token_ids = []\n",
    "            for t in tokens:\n",
    "                token_ids.extend(t.ids)\n",
    "        else:  # Single TokSequence\n",
    "            token_ids = tokens.ids\n",
    "        # ---- Store tempo for average calculation ----\n",
    "        if midi.tempo_changes:\n",
    "            jig_tempos.append(midi.tempo_changes[0].tempo)\n",
    "        else:\n",
    "            jig_tempos.append(120)\n",
    "        # ---- Save tokenized output as before ----\n",
    "        with open(os.path.join(token_folder, fname.replace('.mid', '.json')), \"w\") as fp:\n",
    "            json.dump({'ids': token_ids}, fp)\n",
    "tokenizer.save_params(token_folder)\n",
    "\n",
    "avg_bpm = sum(jig_tempos) / len(jig_tempos) if jig_tempos else 120\n",
    "avg_us_per_quarter = 60_000_000 / avg_bpm\n",
    "print(f\"Jig average BPM: {avg_bpm:.2f}, us/quarter: {avg_us_per_quarter:.2f}\")\n",
    "\n",
    "# === PyTorch Dataset with Padding ===\n",
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, token_folder, min_length=32):\n",
    "        self.files = [\n",
    "            os.path.join(token_folder, f)\n",
    "            for f in os.listdir(token_folder)\n",
    "            if f.endswith(\".json\") and f != \"tokenizer.json\" and f.lower().startswith(\"jigs\")\n",
    "        ]\n",
    "        param_path = os.path.join(token_folder, \"tokenizer.json\")\n",
    "        self.tokenizer = miditok.REMI(params=param_path)\n",
    "        self.sequences = []\n",
    "        skipped = []\n",
    "        for file in self.files:\n",
    "            with open(file, \"r\") as fp:\n",
    "                tok_seq = json.load(fp)\n",
    "            if 'ids' in tok_seq and len(tok_seq['ids']) > 1:\n",
    "                self.sequences.append(tok_seq['ids'])\n",
    "            else:\n",
    "                skipped.append((file, len(tok_seq['ids']) if 'ids' in tok_seq else 'NO IDS'))\n",
    "        print(f\"Loaded {len(self.sequences)} sequences.\")\n",
    "        print(f\"Skipped {len(skipped)} files: {skipped[:10]} ...\")  # show first 10 skipped\n",
    "        if len(self.sequences) == 0:\n",
    "            raise ValueError(\"No sequences found. Try lowering min_length or check tokenized data.\")\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        x = torch.tensor(seq[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "def collate_pad(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    lengths = [len(x) for x in xs]\n",
    "    xs_padded = pad_sequence(xs, batch_first=True, padding_value=0)\n",
    "    ys_padded = pad_sequence(ys, batch_first=True, padding_value=0)\n",
    "    return xs_padded, ys_padded, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "dataset = MIDITokenDataset(token_folder, min_length=1)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True, collate_fn=collate_pad)\n",
    "\n",
    "# === LSTM Model ===\n",
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    def forward(self, x, lengths, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, hidden = self.lstm(packed, hidden)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "vocab_size = len(dataset.tokenizer.vocab)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MusicLSTM(vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# === Training Loop ===\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y, lengths in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y, lengths = x.to(device), y.to(device), lengths.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, _ = model(x, lengths)\n",
    "        out = out.view(-1, vocab_size)\n",
    "        y = y.view(-1)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "# === Generation ===\n",
    "def generate_until_duration_lstm(\n",
    "    model, tokenizer, device, target_seconds=27, temperature=1.0, max_tokens=3000,\n",
    "    tpq=480, tempo_us_per_quarter=500_000\n",
    "):\n",
    "    model.eval()\n",
    "    start_token = list(tokenizer.vocab.values())[0]\n",
    "    seq = [start_token]\n",
    "    input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "    hidden = None\n",
    "    elapsed_seconds = 0\n",
    "    with torch.no_grad():\n",
    "        while elapsed_seconds < target_seconds and len(seq) < max_tokens:\n",
    "            out, hidden = model(input_seq, torch.tensor([len(seq)]).to(device), hidden)\n",
    "            logits = out[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            seq.append(next_token)\n",
    "            input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
    "            if len(seq) % 32 == 0 or elapsed_seconds == 0:\n",
    "                midi_obj = tokenizer.tokens_to_midi([seq])\n",
    "                ticks = midi_obj.end()\n",
    "                elapsed_seconds = ticks / tpq * (tempo_us_per_quarter / 1_000_000)\n",
    "    return seq\n",
    "\n",
    "tokens = generate_until_duration_lstm(\n",
    "    model,\n",
    "    dataset.tokenizer,\n",
    "    device,\n",
    "    target_seconds=27,\n",
    "    temperature=1.0,\n",
    "    max_tokens=3000,\n",
    "    tpq=480,\n",
    "    tempo_us_per_quarter=avg_us_per_quarter\n",
    ")\n",
    "\n",
    "midi = dataset.tokenizer.tokens_to_midi([tokens])\n",
    "midi.dump_midi(\"generated_jig_lstm.mid\")\n",
    "print(\"Saved generated_jig_lstm.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbf03a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration (seconds): 240.50\n"
     ]
    }
   ],
   "source": [
    "# To verify duration\n",
    "from symusic.core import ScoreTick\n",
    "\n",
    "midi_loaded = ScoreTick.from_file(\"generated_jig_lstm.mid\")\n",
    "duration_seconds = midi_loaded.end() / midi_loaded.ticks_per_quarter * 60 / 120\n",
    "print(f\"Duration (seconds): {duration_seconds:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
